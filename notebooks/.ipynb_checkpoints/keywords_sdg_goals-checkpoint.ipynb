{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "\n",
    "#import matplotlib\n",
    "import numpy as np\n",
    "#import missingno as msno\n",
    "#import altair as alt\n",
    "#from vega_datasets import data\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import re\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "import nltk.stem\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/sdg_goal_en.txt\", \"r\") as myfile:\n",
    "    data = myfile.read().replace('\\n', \" \")\n",
    "    data = data.replace('\"', '')\n",
    "\n",
    "splits = data.split('ยง')\n",
    "lst = []\n",
    "for i in splits[0:-1]:\n",
    "    #print(i)\n",
    "    entry = i.split('@')\n",
    "    entry[0] = entry[0].replace('Ziel', '')\n",
    "    entry[0] = entry[0].replace(':', '')\n",
    "    lst.append((entry[0].strip(), entry[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Goal 1</td>\n",
       "      <td>No poverty End poverty in all its forms every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Goal 2</td>\n",
       "      <td>Zero hunger End hunger, achieve food security...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goal 3</td>\n",
       "      <td>Good health and well-being for people Ensure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Goal 4</td>\n",
       "      <td>Quality education Ensure inclusive and equita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Goal 5</td>\n",
       "      <td>Gender equality Achieve gender equality and e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text\n",
       "0  Goal 1   No poverty End poverty in all its forms every...\n",
       "1  Goal 2   Zero hunger End hunger, achieve food security...\n",
       "2  Goal 3   Good health and well-being for people Ensure ...\n",
       "3  Goal 4   Quality education Ensure inclusive and equita...\n",
       "4  Goal 5   Gender equality Achieve gender equality and e..."
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(lst, columns =['id', 'text']) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove integers\n",
    "def drop_integers(s):\n",
    "    return re.sub(r'\\d+', '', s)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals = {\n",
    "1: \"No poverty: End poverty in all its forms everywhere.\", \n",
    "2: \"Zero hunger : End hunger, achieve food security and improved nutrition, and promote sustainable agriculture.\",\n",
    "3: \"Good health and well-being for people Ensure healthy lives and promote well-being for all at all ages.\",\n",
    "4: \"Quality education: Ensure inclusive and equitable quality education and promote lifelong learning opportunities for all.\",\n",
    " 5: \"Gender equality :  Achieve gender equality and empower all women and girls.\",\n",
    " 6: \"Clean water and sanitation : Ensure availability and sustainable management of water and sanitation for all.\",\n",
    " 7: \"Affordable and clean energy :  Ensure access to affordable, reliable, sustainable and modern energy for all.\",\n",
    " 8: \"Decent work and economic growth : Promote sustained, inclusive and sustainable economic growth, full and productive employment and decent work for all.\",\n",
    " 9: \"Industry, Innovation, and Infrastructure : Build resilient infrastructure, promote inclusive and sustainable industrialization, and foster innovation.\",\n",
    " 10: \"Reducing inequalities : Reduce income inequality within and among countries.\",\n",
    " 11: \"Sustainable cities and communities : Make cities and human settlements inclusive, safe, resilient, and sustainable.\",\n",
    " 12: \"Responsible consumption and production : Ensure sustainable consumption and production patterns.\",\n",
    " 13: \"Climate action : Take urgent action to combat climate change and its impacts by regulating emissions and promoting developments in renewable energy.\",\n",
    " 14:\"Life below water : Conserve and sustainably use the oceans, seas and marine resources for sustainable development.\",\n",
    " 15:\"Life on land .  Protect, restore and promote sustainable use of terrestrial ecosystems, sustainably manage forests, combat desertification, and halt and reverse land degradation and halt biodiversity loss.\",\n",
    " 16:\"Peace, justice and strong institutions: Promote peaceful and inclusive societies for sustainable development, provide access to justice for all and build effective, accountable and inclusive institutions at all levels.\",\n",
    "17:\"Partnerships for the goals : Strengthen the means of implementation and revitalize the global partnership for sustainable development.\"  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('By')\n",
    "stop_words.append('including')\n",
    "stop_words.append('dimensions')\n",
    "l = ['appropriate','terms']\n",
    "stop_words.extend(l)\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer( stop_words=stop_words, preprocessor=drop_integers, ngram_range=(1,1))\n",
    "X = vectorizer.fit_transform(df.text)\n",
    "features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: 1  ['poverty', 'poor', 'resources', 'vulnerable', 'reduce', 'extreme']\n",
      "topic: 2  ['food', 'agricultural', 'access', 'markets', 'particular', 'ensure']\n",
      "topic: 3  ['health', 'countries', 'developing', 'access', 'diseases', 'communicable']\n",
      "topic: 4  ['education', 'countries', 'ensure', 'developing', 'sustainable', 'development']\n",
      "topic: 5  ['women', 'girls', 'public', 'equality', 'forms', 'resources']\n",
      "topic: 6  ['water', 'sanitation', 'substantially', 'management', 'reuse', 'achieve']\n",
      "topic: 7  ['energy', 'technology', 'countries', 'developing', 'modern', 'clean']\n",
      "topic: 8  ['growth', 'employment', 'labour', 'economic', 'countries', 'work']\n",
      "topic: 9  ['countries', 'developing', 'development', 'infrastructure', 'sustainable', 'access']\n",
      "topic: 10  ['countries', 'policies', 'developing', 'financial', 'institutions', 'per']\n",
      "topic: 11  ['sustainable', 'persons', 'cities', 'safe', 'number', 'inclusive']\n",
      "topic: 12  ['sustainable', 'countries', 'production', 'consumption', 'taking', 'development']\n",
      "topic: 13  ['climate', 'change', 'countries', 'capacity', 'Climate', 'action']\n",
      "topic: 14  ['marine', 'sustainable', 'resources', 'least', 'use', 'countries']\n",
      "topic: 15  ['sustainable', 'land', 'species', 'biodiversity', 'ecosystems', 'forests']\n",
      "topic: 16  ['institutions', 'levels', 'forms', 'access', 'national', 'violence']\n",
      "topic: 17  ['countries', 'developing', 'least', 'developed', 'development', 'technology']\n"
     ]
    }
   ],
   "source": [
    "cv_dataframe=pd.DataFrame(X.toarray(),columns=features)\n",
    "topic = 1\n",
    "nrdocs = len(X.toarray())\n",
    "for i in range(0,nrdocs):\n",
    "    r = cv_dataframe.loc[i].sort_values(ascending=False)\n",
    "    terms = r.index[0:6]\n",
    "\n",
    "    lst = []\n",
    "    for t in terms:\n",
    "        lst.append(t) \n",
    "    print(f\"topic: {topic}  {lst}\")\n",
    "    topic = topic + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF\n",
    "\n",
    "better results and on count vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfTransformer()\n",
    "X_tfidf = tf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf = pd.DataFrame(X_tfidf.toarray(),columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDG Goal: 1: No poverty: End poverty in all its forms everywhere. \n",
      "\n",
      " Keywords: ['poverty', 'poor', 'living', 'vulnerable', 'extreme', 'resources', 'men', 'everywhere', 'social', 'End', 'forms', 'economic', 'women', 'shocks', 'floors'] \n",
      "\n",
      "\n",
      "SDG Goal: 2: Zero hunger : End hunger, achieve food security and improved nutrition, and promote sustainable agriculture. \n",
      "\n",
      " Keywords: ['agricultural', 'food', 'hunger', 'markets', 'export', 'help', 'banks', 'plant', 'maintain', 'internationally', 'genetic', 'extreme', 'productivity', 'production', 'productive'] \n",
      "\n",
      "\n",
      "SDG Goal: 3: Good health and well-being for people Ensure healthy lives and promote well-being for all at all ages. \n",
      "\n",
      " Keywords: ['health', 'diseases', 'communicable', 'mortality', 'medicines', 'live', 'births', 'vaccines', 'countries', 'essential', 'deaths', 'Agreement', 'low', 'Health', 'well'] \n",
      "\n",
      "\n",
      "SDG Goal: 4: Quality education: Ensure inclusive and equitable quality education and promote lifelong learning opportunities for all. \n",
      "\n",
      " Keywords: ['education', 'vocational', 'primary', 'skills', 'learning', 'ensure', 'technical', 'training', 'countries', 'quality', 'gender', 'boys', 'adults', 'developing', 'youth'] \n",
      "\n",
      "\n",
      "SDG Goal: 5: Gender equality :  Achieve gender equality and empower all women and girls. \n",
      "\n",
      " Keywords: ['women', 'girls', 'equality', 'Action', 'Eliminate', 'empowerment', 'forms', 'sexual', 'reproductive', 'public', 'promotion', 'gender', 'rights', 'economic', 'equal'] \n",
      "\n",
      "\n",
      "SDG Goal: 6: Clean water and sanitation : Ensure availability and sustainable management of water and sanitation for all. \n",
      "\n",
      " Keywords: ['water', 'sanitation', 'wastewater', 'scarcity', 'reuse', 'recycling', 'management', 'substantially', 'efficiency', 'related', 'equitable', 'safe', 'cooperation', 'lakes', 'Lusaka'] \n",
      "\n",
      "\n",
      "SDG Goal: 7: Affordable and clean energy :  Ensure access to affordable, reliable, sustainable and modern energy for all. \n",
      "\n",
      " Keywords: ['energy', 'clean', 'modern', 'technology', 'renewable', 'reliable', 'infrastructure', 'efficiency', 'affordable', 'access', 'developing', 'improvement', 'mix', 'advanced', 'supplying'] \n",
      "\n",
      "\n",
      "SDG Goal: 8: Decent work and economic growth : Promote sustained, inclusive and sustainable economic growth, full and productive employment and decent work for all. \n",
      "\n",
      " Keywords: ['growth', 'labour', 'employment', 'work', 'economic', 'decent', 'child', 'productive', 'secure', 'encourage', 'workers', 'consumption', 'per', 'youth', 'full'] \n",
      "\n",
      "\n",
      "SDG Goal: 9: Industry, Innovation, and Infrastructure : Build resilient infrastructure, promote inclusive and sustainable industrialization, and foster innovation. \n",
      "\n",
      " Keywords: ['industrial', 'countries', 'infrastructure', 'research', 'innovation', 'resilient', 'developing', 'industrialization', 'development', 'sustainable', 'affordable', 'capabilities', 'technological', 'share', 'access'] \n",
      "\n",
      "\n",
      "SDG Goal: 10: Reducing inequalities : Reduce income inequality within and among countries. \n",
      "\n",
      " Keywords: ['policies', 'countries', 'cent', 'institutions', 'inequalities', 'costs', 'migration', 'income', 'economic', 'per', 'higher', 'progressively', 'social', 'developing', 'financial'] \n",
      "\n",
      "\n",
      "SDG Goal: 11: Sustainable cities and communities : Make cities and human settlements inclusive, safe, resilient, and sustainable. \n",
      "\n",
      " Keywords: ['cities', 'persons', 'safe', 'disasters', 'settlements', 'urban', 'transport', 'accessible', 'number', 'sustainable', 'human', 'inclusive', 'older', 'attention', 'integrated'] \n",
      "\n",
      "\n",
      "SDG Goal: 12: Responsible consumption and production : Ensure sustainable consumption and production patterns. \n",
      "\n",
      " Keywords: ['consumption', 'production', 'sustainable', 'impacts', 'taking', 'patterns', 'cycle', 'companies', 'waste', 'account', 'losses', 'countries', 'subsidies', 'food', 'adverse'] \n",
      "\n",
      "\n",
      "SDG Goal: 13: Climate action : Take urgent action to combat climate change and its impacts by regulating emissions and promoting developments in renewable energy. \n",
      "\n",
      " Keywords: ['climate', 'change', 'Climate', 'raising', 'mitigation', 'planning', 'capacity', 'related', 'action', 'capitalization', 'regulating', 'undertaken', 'emissions', 'parties', 'developments'] \n",
      "\n",
      "\n",
      "SDG Goal: 14: Life below water : Conserve and sustainably use the oceans, seas and marine resources for sustainable development. \n",
      "\n",
      " Keywords: ['marine', 'oceans', 'subsidies', 'fishing', 'fisheries', 'sustainable', 'resources', 'sustainably', 'use', 'based', 'scientific', 'least', 'Marine', 'unreported', 'unregulated'] \n",
      "\n",
      "\n",
      "SDG Goal: 15: Life on land .  Protect, restore and promote sustainable use of terrestrial ecosystems, sustainably manage forests, combat desertification, and halt and reverse land degradation and halt biodiversity loss. \n",
      "\n",
      " Keywords: ['biodiversity', 'species', 'land', 'ecosystems', 'halt', 'forests', 'sustainable', 'conservation', 'desertification', 'restore', 'degradation', 'resources', 'poaching', 'reforestation', 'degraded'] \n",
      "\n",
      "\n",
      "SDG Goal: 16: Peace, justice and strong institutions: Promote peaceful and inclusive societies for sustainable development, provide access to justice for all and build effective, accountable and inclusive institutions at all levels. \n",
      "\n",
      " Keywords: ['institutions', 'justice', 'forms', 'violence', 'levels', 'crime', 'inclusive', 'Promote', 'accountable', 'international', 'reduce', 'combat', 'strengthen', 'Strengthen', 'development'] \n",
      "\n",
      "\n",
      "SDG Goal: 17: Partnerships for the goals : Strengthen the means of implementation and revitalize the global partnership for sustainable development. \n",
      "\n",
      " Keywords: ['countries', 'debt', 'South', 'partnerships', 'ODA', 'developing', 'least', 'technology', 'building', 'development', 'developed', 'support', 'Enhance', 'policy', 'goals'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic = 1\n",
    "for i in range(0,nrdocs):\n",
    "    r = df_tf.loc[i].sort_values(ascending=False)\n",
    "    terms = r.index[0:15]\n",
    "\n",
    "    lst = []\n",
    "    for t in terms:\n",
    "        lst.append(t) \n",
    "    print(f\"SDG Goal: {topic}: {goals[topic]} \\n\\n Keywords: {lst} \\n\\n\")\n",
    "    topic = topic + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfTransformer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-264-dd4ca40dd8df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#titles = lda.datasets.load_reuters_titles()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TfidfTransformer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "#titles = lda.datasets.load_reuters_titles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 5468)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 17\n",
      "INFO:lda:vocab_size: 7528\n",
      "INFO:lda:n_words: 9919\n",
      "INFO:lda:n_topics: 17\n",
      "INFO:lda:n_iter: 1500\n",
      "/home/avare/python_envs/gt_recommender/lib/python3.7/site-packages/lda/utils.py:55: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if sparse and not np.issubdtype(doc_word.dtype, int):\n",
      "INFO:lda:<0> log likelihood: -130203\n",
      "INFO:lda:<10> log likelihood: -117856\n",
      "INFO:lda:<20> log likelihood: -115957\n",
      "INFO:lda:<30> log likelihood: -114392\n",
      "INFO:lda:<40> log likelihood: -113431\n",
      "INFO:lda:<50> log likelihood: -112953\n",
      "INFO:lda:<60> log likelihood: -112031\n",
      "INFO:lda:<70> log likelihood: -112175\n",
      "INFO:lda:<80> log likelihood: -111930\n",
      "INFO:lda:<90> log likelihood: -111544\n",
      "INFO:lda:<100> log likelihood: -111501\n",
      "INFO:lda:<110> log likelihood: -111337\n",
      "INFO:lda:<120> log likelihood: -111147\n",
      "INFO:lda:<130> log likelihood: -110882\n",
      "INFO:lda:<140> log likelihood: -110558\n",
      "INFO:lda:<150> log likelihood: -110984\n",
      "INFO:lda:<160> log likelihood: -110755\n",
      "INFO:lda:<170> log likelihood: -110134\n",
      "INFO:lda:<180> log likelihood: -110786\n",
      "INFO:lda:<190> log likelihood: -110924\n",
      "INFO:lda:<200> log likelihood: -110666\n",
      "INFO:lda:<210> log likelihood: -110660\n",
      "INFO:lda:<220> log likelihood: -110477\n",
      "INFO:lda:<230> log likelihood: -110345\n",
      "INFO:lda:<240> log likelihood: -110125\n",
      "INFO:lda:<250> log likelihood: -110539\n",
      "INFO:lda:<260> log likelihood: -110270\n",
      "INFO:lda:<270> log likelihood: -110358\n",
      "INFO:lda:<280> log likelihood: -110343\n",
      "INFO:lda:<290> log likelihood: -110515\n",
      "INFO:lda:<300> log likelihood: -110366\n",
      "INFO:lda:<310> log likelihood: -110566\n",
      "INFO:lda:<320> log likelihood: -110264\n",
      "INFO:lda:<330> log likelihood: -110311\n",
      "INFO:lda:<340> log likelihood: -110085\n",
      "INFO:lda:<350> log likelihood: -110225\n",
      "INFO:lda:<360> log likelihood: -110298\n",
      "INFO:lda:<370> log likelihood: -110067\n",
      "INFO:lda:<380> log likelihood: -109891\n",
      "INFO:lda:<390> log likelihood: -110259\n",
      "INFO:lda:<400> log likelihood: -110184\n",
      "INFO:lda:<410> log likelihood: -110274\n",
      "INFO:lda:<420> log likelihood: -110336\n",
      "INFO:lda:<430> log likelihood: -110167\n",
      "INFO:lda:<440> log likelihood: -110244\n",
      "INFO:lda:<450> log likelihood: -109893\n",
      "INFO:lda:<460> log likelihood: -110269\n",
      "INFO:lda:<470> log likelihood: -110262\n",
      "INFO:lda:<480> log likelihood: -110211\n",
      "INFO:lda:<490> log likelihood: -110450\n",
      "INFO:lda:<500> log likelihood: -110135\n",
      "INFO:lda:<510> log likelihood: -110165\n",
      "INFO:lda:<520> log likelihood: -110315\n",
      "INFO:lda:<530> log likelihood: -110159\n",
      "INFO:lda:<540> log likelihood: -110038\n",
      "INFO:lda:<550> log likelihood: -110046\n",
      "INFO:lda:<560> log likelihood: -109992\n",
      "INFO:lda:<570> log likelihood: -109974\n",
      "INFO:lda:<580> log likelihood: -110104\n",
      "INFO:lda:<590> log likelihood: -110381\n",
      "INFO:lda:<600> log likelihood: -110128\n",
      "INFO:lda:<610> log likelihood: -110491\n",
      "INFO:lda:<620> log likelihood: -110206\n",
      "INFO:lda:<630> log likelihood: -110154\n",
      "INFO:lda:<640> log likelihood: -110009\n",
      "INFO:lda:<650> log likelihood: -110225\n",
      "INFO:lda:<660> log likelihood: -110025\n",
      "INFO:lda:<670> log likelihood: -110288\n",
      "INFO:lda:<680> log likelihood: -110480\n",
      "INFO:lda:<690> log likelihood: -110416\n",
      "INFO:lda:<700> log likelihood: -110320\n",
      "INFO:lda:<710> log likelihood: -110245\n",
      "INFO:lda:<720> log likelihood: -110424\n",
      "INFO:lda:<730> log likelihood: -110199\n",
      "INFO:lda:<740> log likelihood: -110329\n",
      "INFO:lda:<750> log likelihood: -110201\n",
      "INFO:lda:<760> log likelihood: -109963\n",
      "INFO:lda:<770> log likelihood: -110087\n",
      "INFO:lda:<780> log likelihood: -109857\n",
      "INFO:lda:<790> log likelihood: -109771\n",
      "INFO:lda:<800> log likelihood: -109757\n",
      "INFO:lda:<810> log likelihood: -109944\n",
      "INFO:lda:<820> log likelihood: -109901\n",
      "INFO:lda:<830> log likelihood: -110199\n",
      "INFO:lda:<840> log likelihood: -110027\n",
      "INFO:lda:<850> log likelihood: -109892\n",
      "INFO:lda:<860> log likelihood: -110351\n",
      "INFO:lda:<870> log likelihood: -109827\n",
      "INFO:lda:<880> log likelihood: -110215\n",
      "INFO:lda:<890> log likelihood: -109896\n",
      "INFO:lda:<900> log likelihood: -109887\n",
      "INFO:lda:<910> log likelihood: -110190\n",
      "INFO:lda:<920> log likelihood: -110100\n",
      "INFO:lda:<930> log likelihood: -110440\n",
      "INFO:lda:<940> log likelihood: -110136\n",
      "INFO:lda:<950> log likelihood: -109944\n",
      "INFO:lda:<960> log likelihood: -109647\n",
      "INFO:lda:<970> log likelihood: -110088\n",
      "INFO:lda:<980> log likelihood: -109914\n",
      "INFO:lda:<990> log likelihood: -110051\n",
      "INFO:lda:<1000> log likelihood: -110172\n",
      "INFO:lda:<1010> log likelihood: -110138\n",
      "INFO:lda:<1020> log likelihood: -110111\n",
      "INFO:lda:<1030> log likelihood: -110100\n",
      "INFO:lda:<1040> log likelihood: -110095\n",
      "INFO:lda:<1050> log likelihood: -110105\n",
      "INFO:lda:<1060> log likelihood: -109840\n",
      "INFO:lda:<1070> log likelihood: -109760\n",
      "INFO:lda:<1080> log likelihood: -109756\n",
      "INFO:lda:<1090> log likelihood: -109627\n",
      "INFO:lda:<1100> log likelihood: -109667\n",
      "INFO:lda:<1110> log likelihood: -109400\n",
      "INFO:lda:<1120> log likelihood: -109761\n",
      "INFO:lda:<1130> log likelihood: -109672\n",
      "INFO:lda:<1140> log likelihood: -109875\n",
      "INFO:lda:<1150> log likelihood: -109664\n",
      "INFO:lda:<1160> log likelihood: -109953\n",
      "INFO:lda:<1170> log likelihood: -109598\n",
      "INFO:lda:<1180> log likelihood: -110128\n",
      "INFO:lda:<1190> log likelihood: -109747\n",
      "INFO:lda:<1200> log likelihood: -109763\n",
      "INFO:lda:<1210> log likelihood: -109752\n",
      "INFO:lda:<1220> log likelihood: -109775\n",
      "INFO:lda:<1230> log likelihood: -109960\n",
      "INFO:lda:<1240> log likelihood: -109659\n",
      "INFO:lda:<1250> log likelihood: -109501\n",
      "INFO:lda:<1260> log likelihood: -109682\n",
      "INFO:lda:<1270> log likelihood: -109442\n",
      "INFO:lda:<1280> log likelihood: -110086\n",
      "INFO:lda:<1290> log likelihood: -109989\n",
      "INFO:lda:<1300> log likelihood: -109870\n",
      "INFO:lda:<1310> log likelihood: -109785\n",
      "INFO:lda:<1320> log likelihood: -109669\n",
      "INFO:lda:<1330> log likelihood: -109883\n",
      "INFO:lda:<1340> log likelihood: -109937\n",
      "INFO:lda:<1350> log likelihood: -109774\n",
      "INFO:lda:<1360> log likelihood: -109721\n",
      "INFO:lda:<1370> log likelihood: -109859\n",
      "INFO:lda:<1380> log likelihood: -109816\n",
      "INFO:lda:<1390> log likelihood: -109818\n",
      "INFO:lda:<1400> log likelihood: -109697\n",
      "INFO:lda:<1410> log likelihood: -109754\n",
      "INFO:lda:<1420> log likelihood: -109742\n",
      "INFO:lda:<1430> log likelihood: -110041\n",
      "INFO:lda:<1440> log likelihood: -109595\n",
      "INFO:lda:<1450> log likelihood: -109772\n",
      "INFO:lda:<1460> log likelihood: -109509\n",
      "INFO:lda:<1470> log likelihood: -109558\n",
      "INFO:lda:<1480> log likelihood: -109794\n",
      "INFO:lda:<1490> log likelihood: -109795\n",
      "INFO:lda:<1499> log likelihood: -110001\n"
     ]
    }
   ],
   "source": [
    "model = lda.LDA(n_topics=17, n_iter=1500, random_state=1)\n",
    "model.fit(X)  # model.fit_transform(X) is also available\n",
    "topic_word = model.topic_word_  # model.components_ also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5552 is out of bounds for axis 0 with size 5468",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-6069315eccfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_top_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_dist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtopic_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn_top_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Topic {}: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5552 is out of bounds for axis 0 with size 5468"
     ]
    }
   ],
   "source": [
    "n_top_words = 8\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemmer\n",
    "english_stemmer = nltk.stem.SnowballStemmer('german')\n",
    "\n",
    "def stemmer(doc):\n",
    "    return [porter_stemmer.stem(w) for w in analyzer(doc)]\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        # will need to rewrite if pickled - due to lambda\n",
    "        return lambda doc: ([english_stemmer.stem(w) for w in analyzer(doc)])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not a built-in stop list: de",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-3507e2d29338>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                                       analyzer='word', stop_words='de') \n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_envs/gt_recommender/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1199\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_envs/gt_recommender/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0manalyze\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_analyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0mj_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-fd9bd27c15a4>\u001b[0m in \u001b[0;36mbuild_analyzer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mStemmedCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCountVectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_analyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0manalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStemmedCountVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_analyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m# will need to rewrite if pickled - due to lambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menglish_stemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_envs/gt_recommender/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mbuild_analyzer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'word'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stop_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0mtokenize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             self._check_stop_words_consistency(stop_words, preprocess,\n",
      "\u001b[0;32m~/python_envs/gt_recommender/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mget_stop_words\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mstop\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \"\"\"\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_check_stop_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_stop_words_consistency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_envs/gt_recommender/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_check_stop_list\u001b[0;34m(stop)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mENGLISH_STOP_WORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"not a built-in stop list: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not a built-in stop list: de"
     ]
    }
   ],
   "source": [
    "vectorizer_s = StemmedCountVectorizer(min_df=5,  preprocessor=drop_integers,\n",
    "                                      analyzer='word', stop_words='de') \n",
    "\n",
    "X = vectorizer_s.fit_transform(df.text)\n",
    "print(X.shape)\n",
    "print(vectorizer_s.get_feature_names()[0:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Givetastic Recommender",
   "language": "python",
   "name": "gt_recommender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
